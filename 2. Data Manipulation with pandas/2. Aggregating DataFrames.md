## üìö Summary statistics
#### üîΩ .mean()
‚ùì avg of your data

    dogs['height_cm'].mean()
#### üîΩ .median()
‚ùì center of your data

#### üîΩ .min()
‚ùì lower of data

    dogs['date_of_birth'].min()
#### üîΩ .max()
‚ùì highest of data

    dogs['date_of_birth'].min()
#### üîΩ .agg()
‚ùì aggregate: 1. create a function that takes col, 2. apply to subset to return cumputation
`quantile()` to calculate percentages
```py
    # create funct. for agg
    def pct30(column) :
      return column.quantile(0.3)
     
    # apply agg
    dogs['waight_kg'].agg(pct30)
    
    # -----
    # summaries on multiple cols
    ''' we get 30% for both cols '''
    dogs[['height_cm','weight_kg']].agg(pct30)
    
    # ----
    # multiple summaries
    def pct40(column) : 
      return column.quantile(0.40)
      
    # apply 30% and 40% to a col
    dogs['weight_kg'].agg([pct30, pct40])
```
#### üîΩ .cumsum()
‚ùì Comulative sum: sums idx when increassing

    dogs['height_cm'].cumsum()
    ''' orig      after_cumsum
    0  2    ----  0  2
    1  4    ----  1  6
    2  6    ----  2  12'''
#### üîΩ cumulative statistics
‚ùì `.cummax()` `.cummin()` `.cumprod()`
## ü¶ç mean and median
```py
# Print the head of the sales DataFrame
print(sales.head())

# Print the info about the sales DataFrame
print(sales.info())

# Print the mean of weekly_sales
print(sales['weekly_sales'].mean())

# Print the median of weekly_sales
print(sales['weekly_sales'].median())
```
## ü¶ç summarizing dates
```py
# Print the maximum of the date column
print(sales['date'].max())

# Print the minimum of the date column
print(sales['date'].min())
```
## ü¶ç Efficient summaries
- [x] 1). Use the custom iqr function defined for you along with .agg() to print the IQR of the temperature_c column of sales.
- [x] 2). Update the column selection to use the custom iqr function with .agg() to print the IQR of temperature_c, fuel_price_usd_per_l, and unemployment, in that order
- [x] 3). Update the aggregation functions called by .agg(): include iqr and np.median in that order.
```py
# A custom IQR function
'''  an alternative to std deviation 75% - 25%'''
def iqr(column):
    return column.quantile(0.75) - column.quantile(0.25)
    
# Print IQR of the temperature_c column
'''return std deviation from temperature column '''
print(sales['temperature_c'].agg(iqr))
```
output

    16.58
```py
# A custom IQR function
def iqr(column):
    return column.quantile(0.75) - column.quantile(0.25)

# Update to print IQR of temperature_c, fuel_price_usd_per_l, & unemployment
print(sales[["temperature_c", "fuel_price_usd_per_l", "unemployment"]].agg(iqr))
```
output

    temperature_c           16.583
    fuel_price_usd_per_l     0.073
    unemployment             0.565
```py
# Import NumPy and create custom IQR function
import numpy as np
def iqr(column):
    return column.quantile(0.75) - column.quantile(0.25)

# Update to print IQR and median of temperature_c, fuel_price_usd_per_l, & unemployment
print(sales[["temperature_c", "fuel_price_usd_per_l", "unemployment"]].agg([iqr, np.median]))
```
output

                        temperature_c  fuel_price_usd_per_l  unemployment
            iqr            16.583                 0.073         0.565
            median         16.967                 0.743         8.099
## ü¶ç cumulative statistics
department's weekly sales, which will allow you to identify what the total sales were so far as well as what the highest weekly sales were so far.
```py
# Sort sales_1_1 by date
sales_1_1 = sales_1_1.sort_values('date')

# Get the cumulative sum of weekly_sales, add as cum_weekly_sales col
sales_1_1['cum_weekly_sales'] = sales['weekly_sales'].cumsum()

# Get the cumulative max of weekly_sales, add as cum_max_sales col
sales_1_1['cum_max_sales'] = sales['weekly_sales'].cummax()

# See the columns you calculated
print(sales_1_1[["date", "weekly_sales", "cum_weekly_sales", "cum_max_sales"]])
```
## üìö Counting
#### üîΩ .drop_duplicates()
‚ùì df.drop_duplicates(subset='column_name')

    vet_visits.drop_duplicates(subset='name')
    
    # specialize more cols to be unique
    unique_dogs.drop_duplicates(subset=['name','breed'])
#### üîΩ .value_counts()
‚ùì when unique was filtered you may count now

    unique_dogs['breed'].value_counts(sort=True)
#### üîΩ proportions
‚ùì gives percentage from the total table each breed has

    unique_dogs['breed'].value_counts(normalize=True)
## ü¶ç Dropping duplicates 
```py
# Drop duplicate store/type combinations
store_types = sales.drop_duplicates(['store','type'])
print(store_types.head())

# Drop duplicate store/department combinations
store_depts = sales.drop_duplicates(['store','department'])
print(store_depts.head())

# Subset the rows where is_holiday is True and drop duplicate dates
holiday_dates = sales[sales['is_holiday']==True].drop_duplicates('date')

# Print date col of holiday_dates
print(holiday_dates['date'])
```
## ü¶ç Counting categorical variables
- [x] Count the number of stores of each store type in store_types.
- [x] Count the proportion of stores of each store type in store_types.
- [x] Count the number of different departments in store_depts, sorting the counts in descending order.
- [x] Count the proportion of different departments in store_depts, sorting the proportions in descending order.
```py
# Count the number of stores of each type
store_counts = store_types['type'].value_counts()
print(store_counts)

# Get the proportion of stores of each type
store_props = store_types['type'].value_counts(normalize=True)
print(store_props)

# Count the number of each department number and sort
dept_counts_sorted = store_depts['department'].value_counts(sort=True)
print(dept_counts_sorted)

# Get the proportion of departments of each number and sort
dept_props_sorted = store_depts['department'].value_counts(sort=True, normalize=True)
print(dept_props_sorted)
```
## üìö Grouped summary statistics
#### üîΩ .groupby()
‚ùì group by column to not specializing every 'color in colors' to compute smt
    
    '''return avg kg depending color of dog'''
    dogs.groupby('color')['weight_kg'].mean()
    
    # Multiple grouped summaries
    dogs.groupby('color')['weight_kg'].agg([min, max, sum])
    #---
    sales.groupby("type")["weekly_sales"].agg([np.min,np.max,np.mean,np.median])

    
    # group by multiple variables
    dogs.groupby(['color','breed'])['weight_kg'].mean()
    
## ü¶ç What percent of sales occurred at each store type?
```py
'''see what proportion of Walmart's total sales were made at each type.'''
# Calc total weekly sales
sales_all = sales["weekly_sales"].sum()

# Subset for type A stores, calc total weekly sales
sales_A = sales[sales["type"] == "A"]["weekly_sales"].sum()

# Subset for type B stores, calc total weekly sales
sales_B = sales[sales["type"] == "B"]["weekly_sales"].sum()

# Subset for type C stores, calc total weekly sales
sales_C = sales[sales["type"] == "C"]["weekly_sales"].sum()

# Get proportion for each type
sales_propn_by_type = [sales_A, sales_B, sales_C] / sales_all
print(sales_propn_by_type)
```
output

    [0.9097747 0.0902253 0.       ]
## ü¶ç calculations with .groupby()
:neckbeard: perform calculations on data grouped by two variables to see if sales differ by store type depending on if it's a holiday week or not.
```py
# Group by type; calc total weekly sales
sales_by_type = sales.groupby("type")["weekly_sales"].sum()

# Get proportion for each type
sales_propn_by_type = sales_by_type / sum(sales_by_type)
print(sales_propn_by_type)
```
output

    type
    A    0.91
    B    0.09
    Name: weekly_sales, dtype: float64
```py
# From previous step
sales_by_type = sales.groupby("type")["weekly_sales"].sum()

# Group by type and is_holiday; calc total weekly sales
sales_by_type_is_holiday = sales.groupby(["type","is_holiday"])["weekly_sales"].sum()
print(sales_by_type_is_holiday)
```
output

    type  is_holiday
    A     False         2.337e+08
          True          2.360e+04
    B     False         2.318e+07
          True          1.621e+03
## ü¶ç Multiple grouped summaries
```py
# Import numpy with the alias np
import numpy as np

# For each store type, aggregate weekly_sales: get min, max, mean, and median
sales_stats = sales.groupby("type")["weekly_sales"].agg([np.min,np.max,np.mean,np.median])

# Print sales_stats
print(sales_stats)

# For each store type, aggregate unemployment and fuel_price_usd_per_l: get min, max, mean, and median
unemp_fuel_stats = sales.groupby("type")["unemployment","fuel_price_usd_per_l"] \
                                .agg([np.min, np.max, np.mean, np.median])

# Print unemp_fuel_stats
print(unemp_fuel_stats)
```
output

            amin       amax       mean    median
    type                                        
    A    -1098.0  293966.05  23674.667  11943.92
    B     -798.0  232558.51  25696.678  13336.08
    
                unemployment                               fuel_price_usd_per_l                     
                 amin   amax   mean median                 amin   amax   mean median
    type                                                                            
    A           3.879  8.992  7.973  8.067                0.664  1.107  0.745  0.735
    B           7.170  9.765  9.279  9.199                0.760  1.108  0.806  0.803
## üìö Pivot tables
#### üîΩ .pivot_table()
‚ùì same as [üîΩ .groupby()](#-groupby) but easier
‚ùî here `index` would be groupby, and `values` what we searching
```py
     dogs.pivot_table(values='weight_kg',
                     index='color')
                     
     # different statistic
     dogs.pivot_table(values='weight_kg',
                     index='color',
                     aggfunc=np.median)
                     
     # multiple statistics
     dogs.pivot_table(values='weight_kg',
                     index='color',
                     aggfunc=[np.median, np.mean])
                     
     # pivot on two variables
     dogs.pivot_table(values='weight_kg',
                      index='color',
                      columns='breed')
                      
     # filling missing values in pivot table
     dogs.pivot_table(values='weight_kg',
                      index='color',
                      columns='breed',
                      fill_value=0)
                      
     # summing w/ pivot table
     '''return sum of columns and total sum'''
     dogs.pivot_table(values= 'weight_kg',
                      index= 'color',
                      columns= 'breed',
                      fill_value= 0,
                      margin= True)
```
## ü¶ç Pivoting on one variable
```py
# Pivot for mean weekly_sales for each store type
mean_sales_by_type = sales.pivot_table(values='weekly_sales',
                                       index= "type")

# Print mean_sales_by_type
print(mean_sales_by_type)
```
```py
# Import NumPy as np
import numpy as np

# Pivot for mean and median weekly_sales for each store type
mean_med_sales_by_type = sales.pivot_table(values='weekly_sales',
                                           index='type',
                                           aggfunc=[np.mean,np.median])

# Print mean_med_sales_by_type
print(mean_med_sales_by_type)
```
```py
# Pivot for mean weekly_sales by store type and holiday 
mean_sales_by_type_holiday = sales.pivot_table(values='weekly_sales',
                                               index='type',
                                               columns='is_holiday')

# Print mean_sales_by_type_holiday
print(mean_sales_by_type_holiday)
```
## ü¶ç Fill in missing values and sum values with pivot tables
```py
# Print mean weekly_sales by department and type; fill missing values with 0
print(sales.pivot_table(values='weekly_sales',
                        index='type',
                        columns='department',
                        fill_value= 0))
```
output

    department         1           2          3          4          5   ...          95         96         97         98       99
    type                                                                ...                                                      
    A           30961.725   67600.159  17160.003  44285.399  34821.011  ...  123933.787  21367.043  28471.267  12875.423  379.124
    B           44050.627  112958.527  30580.655  51219.654  63236.875  ...   77082.102   9528.538   5828.873    217.428    0.000
