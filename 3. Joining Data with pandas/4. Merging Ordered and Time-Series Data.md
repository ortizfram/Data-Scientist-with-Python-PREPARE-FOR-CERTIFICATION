## üçé Using merge_ordered()
### üëΩ merge_ordered()
‚ùì default outer `from pd`, also use suffixes

‚ùî when to use it==== ordered data / time-series / filling missing values
#### üîΩ fill_method argument
- 'ffill' : for filling w/ previous item value
## ü¶ç Correlation between GDP and S&P500
- [x] 1. Use merge_ordered() to merge gdp and sp500 using a left join on year and date. Save the results as gdp_sp500.
- [x] 1. Print gdp_sp500 and look at the returns for the year 2018.
```py
# Use merge_ordered() to merge gdp and sp500 on year and date
gdp_sp500 = pd.merge_ordered(gdp, sp500, left_on='year', right_on='date', 
                             how='left')

# Print gdp_sp500
print(gdp_sp500)
```
- [x] 2. Use merge_ordered(), again similar to before, to merge gdp and sp500 use the function's ability to interpolate missing data to forward fill the missing value for returns, assigning this table to the variable gdp_sp500.
```py
# Use merge_ordered() to merge gdp and sp500, interpolate missing value
gdp_sp500 = pd.merge_ordered(gdp,sp500, left_on='year', right_on='date', how='left',fill_method='ffill')


# Print gdp_sp500
print (gdp_sp500)
```
- [x] 3. Subset the gdp_sp500 table, select the gdp and returns columns, and save as gdp_returns.
- [x] 3. Print the correlation matrix of the gdp_returns table.
```py
# Use merge_ordered() to merge gdp and sp500, interpolate missing value
gdp_sp500 = pd.merge_ordered(gdp, sp500, left_on='year', right_on='date', 
                             how='left',  fill_method='ffill')

# Subset the gdp and returns columns
gdp_returns = gdp_sp500[['gdp', 'returns']]

# Print gdp_returns correlation
print (gdp_returns.corr())
```
## ü¶ç Phillips curve using merge_ordered()
```py
# Use merge_ordered() to merge inflation, unemployment with inner join
inflation_unemploy = pd.merge_ordered(inflation, unemployment, on='date' ,how='inner')

# Print inflation_unemploy 
print(inflation_unemploy)

# Plot a scatter plot of unemployment_rate vs cpi of inflation_unemploy
inflation_unemploy.plot(kind='scatter', x='unemployment_rate', y='cpi')
plt.show()
```

<img src="https://user-images.githubusercontent.com/51888893/207058548-9c054be2-8d42-4ad0-b7d5-1dcf85199143.png" width=500px>

## ü¶ç merge_ordered() caution, multiple columns
:neckbeard: he frequency of the series are different, the GDP values are quarterly, and the population is yearly. Use the forward fill feature to fill in the missing data. Depending on the order provided, the fill forward will use unintended data to fill in the missing values.
```py
# Merge gdp and pop on date and country with fill and notice rows 2 and 3
ctry_date = pd.merge_ordered(gdp, pop, on=['date','country'],
                             fill_method='ffill')

# Print ctry_date
print(ctry_date)
```
```py
# Merge gdp and pop on country and date with fill
date_ctry = pd.merge_ordered(gdp, pop, on=['country','date'],
                            fill_method='ffill')

# Print date_ctry
print(date_ctry)
```
## üçé Using merge_asof()
‚ùì similar as [merge_ordered](#-mergeordered) but match nearest column values rather than equal values

üëë columns to merge must be sorted
#### üîΩ direction argument
- `forward/backward/nearest`
## ü¶ç Using merge_asof() to study stocks
```py
# Use merge_asof() to merge jpm and wells
jpm_wells = pd.merge_asof(jpm, wells, on='date_time', suffixes=['','_wells'], direction='nearest')


# Use merge_asof() to merge jpm_wells and bac
jpm_wells_bac = pd.merge_asof(jpm_wells, bac, on='date_time',suffixes=['_jpm','_bac'], direction='nearest')


# Compute price diff
price_diffs = jpm_wells_bac.diff()

# Plot the price diff of the close of jpm, wells and bac only
price_diffs.plot(y=['close_jpm','close_wells','close_bac'])
plt.show()
```

<img src="https://user-images.githubusercontent.com/51888893/207072621-1f821544-2cab-4b39-b871-07cf906ab6dd.png" width=500px>

## ü¶ç Using merge_asof() to create dataset
:neckbeard: Use merge_asof() to merge the tables and create a status flag if a quarter was during a recession. Finally, to check your work, plot the data in a bar chart.
```py
# Merge gdp and recession on date using merge_asof()
gdp_recession = pd.merge_asof(gdp, recession, on='date')

# Create a list based on the row value of gdp_recession['econ_status']
is_recession = ['r' if s=='recession' else 'g' for s in gdp_recession['econ_status']]

# Plot a bar chart of gdp_recession
gdp_recession.plot(kind='bar', y='gdp', x='date', color=is_recession, rot=90)
plt.show()
```

<img src="https://user-images.githubusercontent.com/51888893/207088094-6f3393ea-20a4-4d15-86d0-4301b878cc47.png" width=500px>

## ü¶ç merge_asof() and merge_ordered() differences
- merge asof()
  - Has an argument that can be set to
'forward' to select the frst row in the right
table whose key column Is greater than or
equal to the left's.
  - it can be used to do fuzzy matching of dates
between tables.
  - After matching two tables, If there are
missing values at the top of the table from
the right table, this functlon can fill them In.
- both
  - Thls function can set the suffix for
overlapping column names.
  - This functlon can be used when working with
ordered or time-serles data.
- merge ordered
  - It allows for a right Joln during the merge.
  - If It cannot match the rows of the tables
exactly. It can use forward fll to Interpolate
the missing data.
## üçé Selecting data with .query()
example

      stocks_long.query('stock=="disney" or (stock=="nike" and close < 90)')  

## ü¶ç Explore financials with .query()
You have been given a table of financial data from some popular social network companies called social_fin. All of the values are in thousands of US dollars.

Use the .query() method and the IPython shell to explore social_fin and select the True statement.

Possible Answers
- [ ] There 2 rows where the value is greater than $50,000,000K.

      In [5]:
      social_fin.query("value > 50000000")
      Out[5]:

              financial   company  year     value
      5   total_revenue  facebook  2019  70697000
      7    gross_profit  facebook  2019  57927000
      20  total_revenue  facebook  2018  55838000
- [ ] There are 3 rows for total revenue for Facebook.

        In [10]:
        social_fin.query('financial == "total_revenue" & company=="facebook"')
        Out[10]:

          financial   company  year     value
      5   total_revenue  facebook  2019  70697000
      20  total_revenue  facebook  2018  55838000
      35  total_revenue  facebook  2017  40653000
      50  total_revenue  facebook  2016  27638000
- [x] There are 6 rows where the net income has a negative value.

      In [14]:
      social_fin.query('financial == "net_income" & value < 0')
      Out[14]:

           financial  company  year    value
      14  net_income     snap  2019 -1033660
      29  net_income     snap  2018 -1255911
      34  net_income  twitter  2017  -108063
      44  net_income     snap  2017 -3445066
      49  net_income  twitter  2016  -456873
      59  net_income     snap  2016  -514643
- [ ] There are 45 rows, where the gross profit is greater than $100K.

      In [16]:
      social_fin.query('financial == "gross_profit" & value > 100000').count()
      Out[16]:

      financial    11
      company      11
      year         11
      value        11
## ü¶ç Subsetting rows with .query()
üëû 1
```py
# Merge gdp and pop on date and country with fill
gdp_pop = pd.merge_ordered(gdp, pop, on='date', fill_method='ffill')
```
üëû 2
```py
# Merge gdp and pop on date and country with fill
gdp_pop = pd.merge_ordered(gdp, pop, on=['country','date'], fill_method='ffill')

# Add a column named gdp_per_capita to gdp_pop that divides the gdp by pop
gdp_pop["gdp_per_capita"] = gdp_pop['gdp'] / gdp_pop['pop']
```
